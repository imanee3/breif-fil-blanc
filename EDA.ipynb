{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a98327f",
   "metadata": {},
   "source": [
    "## RDF→CSV + standardisation CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "22d5a4e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CTA monthly: (500, 9)\n",
      "CTA daily: (500, 6)\n",
      "Philly mode: (492, 8)\n",
      "Philly route: (10994, 8)\n",
      "✅ Fichiers créés dans data/\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from rdflib import Graph\n",
    "import os\n",
    "\n",
    "# =========================\n",
    "# PATHS (tes fichiers)\n",
    "# =========================\n",
    "CTA_RDF_DAILY_PATH = r\"C:\\Fil Blanc\\CTA Chicago - Ridership - Bus Routes - Daily Type Averages & Totals (RDF).rdf\"\n",
    "CTA_RDF_MONTHLY_PATH = r\"C:\\Fil Blanc\\CTA Chicago - Ridership - Bus Routes - Monthly Day-Type Averages & Totals (RDF).rdf\"\n",
    "\n",
    "PHILLY_MODE_CSV_PATH = r\"C:\\Fil Blanc\\Average_Daily_Ridership_By_Mode - City of Philadelphia.csv\"\n",
    "PHILLY_ROUTE_CSV_PATH = r\"C:\\Fil Blanc\\Average_Daily_Ridership_By_Route - City of Philadelphia.csv\"\n",
    "\n",
    "# =========================\n",
    "# 1) RDF -> DataFrame (CTA)\n",
    "# =========================\n",
    "def rdf_to_df(rdf_path: str) -> pd.DataFrame:\n",
    "    g = Graph()\n",
    "    # rdflib détecte le format automatiquement pour ces fichiers\n",
    "    g.parse(rdf_path)\n",
    "\n",
    "    rows = {}\n",
    "    for s, p, o in g:\n",
    "        p_str = str(p)\n",
    "\n",
    "        # ignorer metadata RDF\n",
    "        if p_str.endswith(\"rdf-syntax-ns#type\") or p_str.endswith(\"/terms#rowID\"):\n",
    "            continue\n",
    "\n",
    "        key = p_str.split(\"/\")[-1]\n",
    "        if \"#\" in key:\n",
    "            key = key.split(\"#\")[-1]\n",
    "\n",
    "        rows.setdefault(str(s), {})[key] = str(o)\n",
    "\n",
    "    return pd.DataFrame.from_dict(rows, orient=\"index\").reset_index(drop=True)\n",
    "\n",
    "# =========================\n",
    "# 2) CTA Monthly -> table analytiques DayType\n",
    "# =========================\n",
    "def rdf_monthly_chicago_to_df(file_path):\n",
    "    g = Graph()\n",
    "    g.parse(file_path, format=\"xml\")\n",
    "\n",
    "    data = {}\n",
    "\n",
    "    for s, p, o in g:\n",
    "        s = str(s)\n",
    "        p = str(p)\n",
    "        o = str(o)\n",
    "\n",
    "        if s not in data:\n",
    "            data[s] = {\n",
    "                \"subject\": s,\n",
    "                \"city\": \"Chicago\"\n",
    "            }\n",
    "\n",
    "        field = p.split(\"/\")[-1]\n",
    "\n",
    "        if field in [\n",
    "            \"route\",\n",
    "            \"routename\",\n",
    "            \"month_beginning\",\n",
    "            \"avg_weekday_rides\",\n",
    "            \"avg_saturday_rides\",\n",
    "            \"avg_sunday_holiday_rides\",\n",
    "            \"monthtotal\"\n",
    "        ]:\n",
    "            data[s][field] = o\n",
    "\n",
    "    df = pd.DataFrame(data.values())\n",
    "\n",
    "    df[\"month_beginning\"] = pd.to_datetime(df[\"month_beginning\"], errors=\"coerce\")\n",
    "\n",
    "    numeric_cols = [\n",
    "        \"avg_weekday_rides\",\n",
    "        \"avg_saturday_rides\",\n",
    "        \"avg_sunday_holiday_rides\",\n",
    "        \"monthtotal\"\n",
    "    ]\n",
    "\n",
    "    for col in numeric_cols:\n",
    "        df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "\n",
    "    return df\n",
    "\n",
    "df_Monthly = rdf_monthly_chicago_to_df(\"CTA Chicago - Ridership - Bus Routes - Monthly Day-Type Averages & Totals (RDF).rdf\")\n",
    "\n",
    "# =========================\n",
    "# 3) CTA Daily -> table journalière\n",
    "# =========================\n",
    "def build_cta_daily(rdf_path: str) -> pd.DataFrame:\n",
    "    df = rdf_to_df(rdf_path)\n",
    "\n",
    "    df[\"Date\"] = pd.to_datetime(df[\"date\"], errors=\"coerce\").dt.date\n",
    "    df[\"Ridership\"] = pd.to_numeric(df[\"rides\"], errors=\"coerce\")\n",
    "\n",
    "    df = df.rename(columns={\"route\": \"RouteID\"})\n",
    "    df[\"City\"] = \"Chicago\"\n",
    "    df[\"Mode\"] = \"Bus\"\n",
    "\n",
    "    # W/A/U -> labels\n",
    "    day_map = {\"W\": \"Weekday\", \"A\": \"Saturday\", \"U\": \"Sunday/Holiday\"}\n",
    "    df[\"DayType\"] = df[\"daytype\"].map(day_map).fillna(df[\"daytype\"])\n",
    "\n",
    "    out = df[[\"City\",\"Mode\",\"Date\",\"RouteID\",\"DayType\",\"Ridership\"]].copy()\n",
    "    return out\n",
    "\n",
    "# =========================\n",
    "# 4) Philly By Mode -> standardisation\n",
    "# =========================\n",
    "def build_philly_monthly_by_mode(csv_path: str) -> pd.DataFrame:\n",
    "    df = pd.read_csv(csv_path)\n",
    "\n",
    "    # construire une date mensuelle standard (YYYY-MM-01)\n",
    "    df[\"MonthBeginning\"] = pd.to_datetime(\n",
    "        df[\"Calendar_Year\"].astype(str) + \"-\" +\n",
    "        df[\"Calendar_Month\"].astype(str).str.zfill(2) + \"-01\",\n",
    "        errors=\"coerce\"\n",
    "    ).dt.date\n",
    "\n",
    "    df[\"AverageDailyRidership\"] = pd.to_numeric(df[\"Average_Daily_Ridership\"], errors=\"coerce\")\n",
    "\n",
    "    out = pd.DataFrame({\n",
    "        \"City\": \"Philadelphia\",\n",
    "        \"Mode\": df[\"Mode\"],\n",
    "        \"MonthBeginning\": df[\"MonthBeginning\"],\n",
    "        \"DayType\": \"All\",\n",
    "        \"RouteID\": \"ALL\",\n",
    "        \"RouteName\": \"ALL\",\n",
    "        \"AverageDailyRidership\": df[\"AverageDailyRidership\"],\n",
    "        \"Source\": df.get(\"Source\", pd.Series([\"\"] * len(df)))\n",
    "    })\n",
    "    return out\n",
    "\n",
    "# =========================\n",
    "# 5) Philly By Route -> standardisation\n",
    "# =========================\n",
    "def build_philly_monthly_by_route(csv_path: str) -> pd.DataFrame:\n",
    "    df = pd.read_csv(csv_path)\n",
    "\n",
    "    df[\"MonthBeginning\"] = pd.to_datetime(\n",
    "        df[\"Calendar_Year\"].astype(str) + \"-\" +\n",
    "        df[\"Calendar_Month\"].astype(str).str.zfill(2) + \"-01\",\n",
    "        errors=\"coerce\"\n",
    "    ).dt.date\n",
    "\n",
    "    df[\"AverageDailyRidership\"] = pd.to_numeric(df[\"Average_Daily_Ridership\"], errors=\"coerce\")\n",
    "\n",
    "    # Ici, le CSV \"by route\" n’a pas Mode => on met \"Bus\" par défaut\n",
    "    out = pd.DataFrame({\n",
    "        \"City\": \"Philadelphia\",\n",
    "        \"Mode\": \"Bus\",\n",
    "        \"MonthBeginning\": df[\"MonthBeginning\"],\n",
    "        \"DayType\": \"All\",\n",
    "        \"RouteID\": df[\"Route\"].astype(str),\n",
    "        \"RouteName\": df[\"Route\"].astype(str),\n",
    "        \"AverageDailyRidership\": df[\"AverageDailyRidership\"],\n",
    "        \"Source\": df.get(\"Source\", pd.Series([\"\"] * len(df)))\n",
    "    })\n",
    "    return out\n",
    "\n",
    "# =========================\n",
    "# RUN + EXPORT\n",
    "# =========================\n",
    "cta_monthly = build_cta_monthly_by_daytype(CTA_RDF_MONTHLY_PATH)\n",
    "cta_daily = build_cta_daily(CTA_RDF_DAILY_PATH)\n",
    "philly_mode = build_philly_monthly_by_mode(PHILLY_MODE_CSV_PATH)\n",
    "philly_route = build_philly_monthly_by_route(PHILLY_ROUTE_CSV_PATH)\n",
    "\n",
    "# Afficher tailles (vérification)\n",
    "print(\"CTA monthly:\", df_Monthly.shape)\n",
    "print(\"CTA daily:\", cta_daily.shape)\n",
    "print(\"Philly mode:\", philly_mode.shape)\n",
    "print(\"Philly route:\", philly_route.shape)\n",
    "\n",
    "# Export CSV\n",
    "\n",
    "\n",
    "OUTPUT_DIR = \"data\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "df_Monthly.to_csv(\"data/chicago_cta_monthly_by_daytype.csv\", index=False)\n",
    "cta_daily.to_csv(\"data/chicago_cta_daily.csv\", index=False)\n",
    "philly_mode.to_csv(\"data/philadelphia_monthly_by_mode.csv\", index=False)\n",
    "philly_route.to_csv(\"data/philadelphia_monthly_by_route.csv\", index=False)\n",
    "\n",
    "print(\"✅ Fichiers créés dans data/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "867f2b09",
   "metadata": {},
   "source": [
    "## CTA Bus Tracker (Chicago) — template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cdf96a08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CTA vehicles: (216, 20)\n",
      "CTA routes with errors: (59, 2)\n",
      "✅ data/cta_realtime_vehicles.csv créé\n",
      "✅ data/cta_realtime_errors.csv créé (routes problématiques)\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import datetime, timezone\n",
    "import os\n",
    "import time\n",
    "\n",
    "CTA_API_KEY = \"D8yuKxkdzXiULT4ZxyKPZL5gm\"\n",
    "BASE = \"https://www.ctabustracker.com/bustime/api/v3/\"\n",
    "\n",
    "def cta_call(endpoint, **params):\n",
    "    params[\"key\"] = CTA_API_KEY\n",
    "    params[\"format\"] = \"json\"\n",
    "    r = requests.get(BASE + endpoint, params=params, timeout=30)\n",
    "    r.raise_for_status()\n",
    "    data = r.json().get(\"bustime-response\", {})\n",
    "    if \"error\" in data and data[\"error\"]:\n",
    "        msg = data[\"error\"][0].get(\"msg\", str(data[\"error\"][0]))\n",
    "        raise ValueError(msg)\n",
    "    return data\n",
    "\n",
    "def cta_routes():\n",
    "    data = cta_call(\"getroutes\")\n",
    "    routes = data.get(\"routes\", [])\n",
    "    if not routes:\n",
    "        raise ValueError(\"Aucune route retournée.\")\n",
    "    df = pd.json_normalize(routes)\n",
    "\n",
    "    # Sécuriser la colonne rt\n",
    "    df[\"rt\"] = df[\"rt\"].astype(str).str.strip()\n",
    "    df = df[df[\"rt\"].notna() & (df[\"rt\"] != \"\")]\n",
    "\n",
    "    return df\n",
    "\n",
    "def cta_vehicles_safe():\n",
    "    routes_df = cta_routes()\n",
    "    route_ids = routes_df[\"rt\"].tolist()\n",
    "\n",
    "    frames = []\n",
    "    errors = []\n",
    "    snap = datetime.now(timezone.utc)\n",
    "\n",
    "    for rt in route_ids:\n",
    "        try:\n",
    "            data = cta_call(\"getvehicles\", rt=rt)\n",
    "            veh = data.get(\"vehicle\", [])\n",
    "            if veh:\n",
    "                df = pd.json_normalize(veh)\n",
    "                df[\"snapshot_ts\"] = snap\n",
    "                df[\"City\"] = \"Chicago\"\n",
    "                frames.append(df)\n",
    "        except Exception as e:\n",
    "            errors.append({\"route\": rt, \"error\": str(e)})\n",
    "\n",
    "        # petite pause pour éviter rate-limit\n",
    "        time.sleep(0.1)\n",
    "\n",
    "    if not frames:\n",
    "        raise ValueError(\"Aucun véhicule récupéré sur toutes les routes (très rare).\")\n",
    "\n",
    "    vehicles_df = pd.concat(frames, ignore_index=True)\n",
    "    errors_df = pd.DataFrame(errors)\n",
    "\n",
    "    return vehicles_df, errors_df\n",
    "\n",
    "# ===== RUN =====\n",
    "cta_df, cta_errors = cta_vehicles_safe()\n",
    "print(\"CTA vehicles:\", cta_df.shape)\n",
    "print(\"CTA routes with errors:\", cta_errors.shape)\n",
    "\n",
    "# ===== EXPORT =====\n",
    "os.makedirs(\"data\", exist_ok=True)\n",
    "cta_df.to_csv(\"data/cta_realtime_vehicles.csv\", index=False)\n",
    "cta_errors.to_csv(\"data/cta_realtime_errors.csv\", index=False)\n",
    "\n",
    "print(\"✅ data/cta_realtime_vehicles.csv créé\")\n",
    "print(\"✅ data/cta_realtime_errors.csv créé (routes problématiques)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abcfbe7d",
   "metadata": {},
   "source": [
    "## SEPTA TransitView (Philadelphia) — template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9d1eb06c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEPTA vehicles: (1, 87)\n",
      "✅ data/septa_realtime_vehicles.csv créé\n"
     ]
    }
   ],
   "source": [
    "import requests, pandas as pd\n",
    "from datetime import datetime, timezone\n",
    "import os\n",
    "\n",
    "SEPTA_URL = \"https://www3.septa.org/api/TransitViewAll/\"\n",
    "\n",
    "def fetch_septa_vehicles():\n",
    "    r = requests.get(SEPTA_URL, timeout=30)\n",
    "    r.raise_for_status()\n",
    "    data = r.json()\n",
    "\n",
    "    rows = []\n",
    "    for mode, vehicles in data.items():\n",
    "        if isinstance(vehicles, list):\n",
    "            for v in vehicles:\n",
    "                v[\"mode\"] = mode\n",
    "                rows.append(v)\n",
    "\n",
    "    if not rows:\n",
    "        raise ValueError(\"⚠️ AUCUN véhicule retourné par l’API SEPTA\")\n",
    "\n",
    "    df = pd.json_normalize(rows)\n",
    "    df[\"snapshot_ts\"] = datetime.now(timezone.utc)\n",
    "    df[\"City\"] = \"Philadelphia\"\n",
    "    return df\n",
    "\n",
    "septa_df = fetch_septa_vehicles()\n",
    "print(\"SEPTA vehicles:\", septa_df.shape)\n",
    "\n",
    "os.makedirs(\"data\", exist_ok=True)\n",
    "septa_df.to_csv(\"data/septa_realtime_vehicles.csv\", index=False)\n",
    "print(\"✅ data/septa_realtime_vehicles.csv créé\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74cf4be4",
   "metadata": {},
   "source": [
    "## Néttoyage "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9d1d02f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colonnes normalisées : ['108', 't4', 't1', '103', '51', '47', '17', '53', '37', '33', '117', 'l1owl', '23', '29', '52', 'blvddir', 'g1', '20', '25', 't5', '109', '42', '125', '63', '9', '18', '66', '93', '119', '57', '12', '14', '45', '54', '60', '65', 'd1', 'l1', 'm1', '55', '115', '104', '114', '82', 'd2', '96', 't5bus', '4', '58', '41', 'b1owl', '61', '5', '48', '56', '139', '6', '79', '124', '75', '7', '113', 'k', '22', 't2', '99', '132', '67', 't3', '73', '2', '31', '16', '59', '123', '30', '39', '3', '46', 'b1', '27', '38', '49', '68', 'mode', 'snapshotts', 'city']\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": " Colonne VehicleId introuvable après normalisation. Colonnes disponibles : ['108', 't4', 't1', '103', '51', '47', '17', '53', '37', '33', '117', 'l1owl', '23', '29', '52', 'blvddir', 'g1', '20', '25', 't5', '109', '42', '125', '63', '9', '18', '66', '93', '119', '57', '12', '14', '45', '54', '60', '65', 'd1', 'l1', 'm1', '55', '115', '104', '114', '82', 'd2', '96', 't5bus', '4', '58', '41', 'b1owl', '61', '5', '48', '56', '139', '6', '79', '124', '75', '7', '113', 'k', '22', 't2', '99', '132', '67', 't3', '73', '2', '31', '16', '59', '123', '30', '39', '3', '46', 'b1', '27', '38', '49', '68', 'mode', 'snapshotts', 'city']",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[41]\u001b[39m\u001b[32m, line 137\u001b[39m\n\u001b[32m    134\u001b[39m \u001b[38;5;66;03m# 2) DÉTECTER LA COLONNE ID VÉHICULE\u001b[39;00m\n\u001b[32m    135\u001b[39m \u001b[38;5;66;03m# après normalisation, on cherche \"vehicleid\"\u001b[39;00m\n\u001b[32m    136\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mvehicleid\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m septa_rt.columns:\n\u001b[32m--> \u001b[39m\u001b[32m137\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    138\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m Colonne VehicleId introuvable après normalisation. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    139\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mColonnes disponibles : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(septa_rt.columns)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    140\u001b[39m     )\n\u001b[32m    142\u001b[39m \u001b[38;5;66;03m# 3) RENOMMER PROPREMENT EN VehicleID\u001b[39;00m\n\u001b[32m    143\u001b[39m septa_rt = septa_rt.rename(columns={\u001b[33m\"\u001b[39m\u001b[33mvehicleid\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mVehicleID\u001b[39m\u001b[33m\"\u001b[39m})\n",
      "\u001b[31mValueError\u001b[39m:  Colonne VehicleId introuvable après normalisation. Colonnes disponibles : ['108', 't4', 't1', '103', '51', '47', '17', '53', '37', '33', '117', 'l1owl', '23', '29', '52', 'blvddir', 'g1', '20', '25', 't5', '109', '42', '125', '63', '9', '18', '66', '93', '119', '57', '12', '14', '45', '54', '60', '65', 'd1', 'l1', 'm1', '55', '115', '104', '114', '82', 'd2', '96', 't5bus', '4', '58', '41', 'b1owl', '61', '5', '48', '56', '139', '6', '79', '124', '75', '7', '113', 'k', '22', 't2', '99', '132', '67', 't3', '73', '2', '31', '16', '59', '123', '30', '39', '3', '46', 'b1', '27', '38', '49', '68', 'mode', 'snapshotts', 'city']"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# =========================\n",
    "# PATHS (fichiers uploadés)\n",
    "# =========================\n",
    "FILES = {\n",
    "    \"chi_daily\": \"C:\\\\Fil Blanc\\\\data\\\\chicago_cta_daily.csv\",\n",
    "    \"chi_monthly\": \"C:\\\\Fil Blanc\\\\data\\\\chicago_cta_monthly_by_daytype.csv\",\n",
    "    \"phl_route\": \"C:\\\\Fil Blanc\\\\data\\\\philadelphia_monthly_by_route.csv\",\n",
    "    \"phl_mode\": \"C:\\\\Fil Blanc\\\\data\\\\philadelphia_monthly_by_mode.csv\",\n",
    "    \"cta_rt\": \"C:\\\\Fil Blanc\\\\data\\\\cta_realtime_vehicles.csv\",\n",
    "    \"septa_rt\": \"C:\\\\Fil Blanc\\\\data\\\\septa_realtime_vehicles.csv\",\n",
    "}\n",
    "\n",
    "OUT_DIR = \"C:\\\\Fil Blanc\\\\data\\\\cleaned\"\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "# =========================\n",
    "# HELPERS\n",
    "# =========================\n",
    "def clean_str(df, cols):\n",
    "    for c in cols:\n",
    "        if c in df.columns:\n",
    "            df[c] = df[c].astype(str).str.strip()\n",
    "            df.loc[df[c].isin([\"\", \"nan\", \"None\"]), c] = pd.NA\n",
    "    return df\n",
    "\n",
    "def clean_num(df, cols):\n",
    "    for c in cols:\n",
    "        if c in df.columns:\n",
    "            df[c] = pd.to_numeric(df[c], errors=\"coerce\").fillna(0)\n",
    "    return df\n",
    "\n",
    "# =========================\n",
    "# 1) CHICAGO DAILY\n",
    "# =========================\n",
    "chi_daily = pd.read_csv(FILES[\"chi_daily\"])\n",
    "chi_daily[\"Date\"] = pd.to_datetime(chi_daily[\"Date\"], errors=\"coerce\")\n",
    "chi_daily = clean_str(chi_daily, [\"RouteID\", \"DayType\", \"City\", \"Mode\"])\n",
    "chi_daily = clean_num(chi_daily, [\"Ridership\"])\n",
    "chi_daily = chi_daily.dropna(subset=[\"Date\", \"RouteID\"])\n",
    "chi_daily = chi_daily.drop_duplicates(subset=[\"Date\", \"RouteID\", \"DayType\"])\n",
    "\n",
    "# =========================\n",
    "# 2) CHICAGO MONTHLY BY DAYTYPE\n",
    "# =========================\n",
    "chi_monthly = pd.read_csv(FILES[\"chi_monthly\"])\n",
    "# 1) supprimer subject\n",
    "if \"subject\" in chi_monthly.columns:\n",
    "    chi_monthly = chi_monthly.drop(columns=[\"subject\"])\n",
    "\n",
    "# 2) nettoyer noms (optionnel mais propre)\n",
    "chi_monthly.columns = (\n",
    "    chi_monthly.columns\n",
    "    .str.strip()\n",
    "    .str.lower()\n",
    "    .str.replace(\" \", \"_\")\n",
    ")\n",
    "\n",
    "# 3) conversions types\n",
    "chi_monthly[\"month_beginning\"] = pd.to_datetime(chi_monthly[\"month_beginning\"], errors=\"coerce\")\n",
    "\n",
    "# route = identifiant de ligne\n",
    "chi_monthly[\"route\"] = chi_monthly[\"route\"].astype(str).str.strip()\n",
    "chi_monthly[\"routename\"] = chi_monthly[\"routename\"].astype(str).str.strip()\n",
    "chi_monthly[\"city\"] = chi_monthly[\"city\"].astype(str).str.strip()\n",
    "\n",
    "# numériques (rides + total)\n",
    "num_cols = [\n",
    "    \"monthtotal\",\n",
    "    \"avg_weekday_rides\",\n",
    "    \"avg_saturday_rides\",\n",
    "    \"avg_sunday_holiday_rides\"\n",
    "]\n",
    "for c in num_cols:\n",
    "    if c in chi_monthly.columns:\n",
    "        chi_monthly[c] = pd.to_numeric(chi_monthly[c], errors=\"coerce\").fillna(0)\n",
    "\n",
    "# 4) supprimer lignes invalides\n",
    "chi_monthly = chi_monthly.dropna(subset=[\"month_beginning\"])\n",
    "chi_monthly = chi_monthly[chi_monthly[\"route\"].notna() & (chi_monthly[\"route\"] != \"\")]\n",
    "\n",
    "# 5) supprimer doublons (clé correcte pour ce dataset)\n",
    "chi_monthly = chi_monthly.drop_duplicates(subset=[\"month_beginning\", \"route\"], keep=\"last\")\n",
    "# =========================\n",
    "# 3) PHILADELPHIA MONTHLY BY ROUTE\n",
    "# =========================\n",
    "phl_route = pd.read_csv(FILES[\"phl_route\"])\n",
    "phl_route[\"MonthBeginning\"] = pd.to_datetime(phl_route[\"MonthBeginning\"], errors=\"coerce\")\n",
    "phl_route = clean_str(phl_route, [\"RouteID\", \"RouteName\", \"City\", \"Mode\"])\n",
    "phl_route = clean_num(phl_route, [\"AverageDailyRidership\"])\n",
    "phl_route = phl_route.dropna(subset=[\"MonthBeginning\", \"RouteID\"])\n",
    "phl_route = phl_route.drop_duplicates(subset=[\"MonthBeginning\", \"RouteID\"])\n",
    "\n",
    "# =========================\n",
    "# 4) PHILADELPHIA MONTHLY BY MODE\n",
    "# =========================\n",
    "phl_mode = pd.read_csv(FILES[\"phl_mode\"])\n",
    "phl_mode[\"MonthBeginning\"] = pd.to_datetime(phl_mode[\"MonthBeginning\"], errors=\"coerce\")\n",
    "phl_mode = clean_str(phl_mode, [\"Mode\", \"City\"])\n",
    "phl_mode = clean_num(phl_mode, [\"AverageDailyRidership\"])\n",
    "phl_mode = phl_mode.dropna(subset=[\"MonthBeginning\", \"Mode\"])\n",
    "phl_mode = phl_mode.drop_duplicates(subset=[\"MonthBeginning\", \"Mode\"])\n",
    "\n",
    "# =========================\n",
    "# 5) CTA REALTIME\n",
    "# =========================\n",
    "cta_rt = pd.read_csv(FILES[\"cta_rt\"])\n",
    "if \"snapshot_ts\" in cta_rt.columns:\n",
    "    cta_rt[\"snapshot_ts\"] = pd.to_datetime(cta_rt[\"snapshot_ts\"], errors=\"coerce\", utc=True)\n",
    "cta_rt = clean_str(cta_rt, [\"vid\", \"rt\"])\n",
    "cta_rt = cta_rt.dropna(subset=[\"vid\", \"rt\"])\n",
    "cta_rt = cta_rt.drop_duplicates(subset=[\"snapshot_ts\", \"vid\"])\n",
    "\n",
    "# =========================\n",
    "# 6) SEPTA REALTIME\n",
    "# =========================\n",
    "septa_rt = pd.read_csv(FILES[\"septa_rt\"])\n",
    "\n",
    "# 1) NORMALISER TOUS LES NOMS DE COLONNES\n",
    "# (supprime espaces, casse, tirets, etc.)\n",
    "septa_rt.columns = (\n",
    "    septa_rt.columns\n",
    "    .str.strip()\n",
    "    .str.replace(\" \", \"\")\n",
    "    .str.replace(\"-\", \"\")\n",
    "    .str.replace(\"_\", \"\")\n",
    "    .str.lower()\n",
    ")\n",
    "\n",
    "print(\"Colonnes normalisées :\", list(septa_rt.columns))\n",
    "\n",
    "# 2) DÉTECTER LA COLONNE ID VÉHICULE\n",
    "# après normalisation, on cherche \"vehicleid\"\n",
    "if \"vehicleid\" not in septa_rt.columns:\n",
    "    raise ValueError(\n",
    "        \" Colonne VehicleId introuvable après normalisation. \"\n",
    "        f\"Colonnes disponibles : {list(septa_rt.columns)}\"\n",
    "    )\n",
    "\n",
    "# 3) RENOMMER PROPREMENT EN VehicleID\n",
    "septa_rt = septa_rt.rename(columns={\"vehicleid\": \"VehicleID\"})\n",
    "\n",
    "# 4) GÉRER snapshot_ts (s'il existe)\n",
    "if \"snapshotts\" in septa_rt.columns:\n",
    "    septa_rt = septa_rt.rename(columns={\"snapshotts\": \"snapshot_ts\"})\n",
    "    septa_rt[\"snapshot_ts\"] = pd.to_datetime(\n",
    "        septa_rt[\"snapshot_ts\"], errors=\"coerce\", utc=True\n",
    "    )\n",
    "\n",
    "# 5) NETTOYER VehicleID\n",
    "septa_rt[\"VehicleID\"] = septa_rt[\"VehicleID\"].astype(str).str.strip()\n",
    "septa_rt.loc[\n",
    "    septa_rt[\"VehicleID\"].isin([\"\", \"nan\", \"none\"]),\n",
    "    \"VehicleID\"\n",
    "] = pd.NA\n",
    "\n",
    "# 6) SUPPRIMER LIGNES INVALIDES\n",
    "septa_rt = septa_rt.dropna(subset=[\"VehicleID\"])\n",
    "\n",
    "# 7) SUPPRIMER DOUBLONS\n",
    "if \"snapshot_ts\" in septa_rt.columns:\n",
    "    septa_rt = septa_rt.drop_duplicates(subset=[\"snapshot_ts\", \"VehicleID\"])\n",
    "else:\n",
    "    septa_rt = septa_rt.drop_duplicates(subset=[\"VehicleID\"])\n",
    "\n",
    "\n",
    "# =========================\n",
    "# EXPORT\n",
    "# =========================\n",
    "chi_daily.to_csv(f\"{OUT_DIR}/chicago_cta_daily_clean.csv\", index=False)\n",
    "chi_monthly.to_csv(f\"{OUT_DIR}/chicago_cta_monthly_by_daytype_clean.csv\", index=False)\n",
    "phl_route.to_csv(f\"{OUT_DIR}/philadelphia_monthly_by_route_clean.csv\", index=False)\n",
    "phl_mode.to_csv(f\"{OUT_DIR}/philadelphia_monthly_by_mode_clean.csv\", index=False)\n",
    "cta_rt.to_csv(f\"{OUT_DIR}/cta_realtime_vehicles_clean.csv\", index=False)\n",
    "septa_rt.to_csv(f\"{OUT_DIR}/septa_realtime_vehicles_clean.csv\", index=False)\n",
    "\n",
    "print(\"✅ Nettoyage terminé\")\n",
    "print(\"Chicago daily:\", chi_daily.shape)\n",
    "print(\"Chicago monthly:\", chi_monthly.shape)\n",
    "print(\"Philly by route:\", phl_route.shape)\n",
    "print(\"Philly by mode:\", phl_mode.shape)\n",
    "print(\"CTA realtime:\", cta_rt.shape)\n",
    "print(\"SEPTA realtime:\", septa_rt.shape)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
